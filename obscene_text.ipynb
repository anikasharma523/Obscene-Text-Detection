{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25g1x_70tk7D",
        "outputId": "b6f605c2-ae7e-428b-8f5b-3d7b4a8dd744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import string, re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "id": "25g1x_70tk7D"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd29b193",
        "outputId": "4a1e1e91-2925-48e9-91dd-252814061abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow pandas matplotlib scikit-learn"
      ],
      "id": "fd29b193"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "598c8f43"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "id": "598c8f43"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBpI3zJ8s3mB",
        "outputId": "ef76beb6-4d9f-4867-d810-2fe7b72bab39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "eBpI3zJ8s3mB"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a9287400"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/IR_Assignment/Project/train.csv')"
      ],
      "id": "a9287400"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dcJ0DpQCtds7"
      },
      "outputs": [],
      "source": [
        "#normalization\n",
        "def lower_case(lines):\n",
        "  lines=lines.lower()\n",
        "  return lines\n",
        "\n",
        "#remove punctuations\n",
        "def remove_punctuation(text):\n",
        "  text=\"\".join([char for char in text if char not in string.punctuation])\n",
        "  text=re.sub('[0-9]+', '', text)\n",
        "  return text\n",
        "\n",
        "#removing stopwords\n",
        "def remove_stpwords(text):\n",
        "  text = [word for word in text if word not in stopwords]\n",
        "  return text\n",
        "\n",
        "#creating tokens\n",
        "def tokenization(text):\n",
        "  text=text.strip()\n",
        "  text = re.split('\\W+', text)\n",
        "  return text\n",
        "\n",
        "#porter stemming\n",
        "def stemming(text):\n",
        "  text = [nltk.PorterStemmer().stem(word) for word in text]\n",
        "  return text\n",
        "\n",
        "#lemmatization\n",
        "def lemmatizer(text):\n",
        "  text = [nltk.WordNetLemmatizer().lemmatize(word) for word in text]\n",
        "  return text"
      ],
      "id": "dcJ0DpQCtds7"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y-_VfUxRtg9r"
      },
      "outputs": [],
      "source": [
        "#Cleaning the document and removing punctuation,stopwords,lowering the case,tokenizing, stemming and performing lemmatization\n",
        "def cleaning_doc(lines):\n",
        "  text = remove_punctuation(lines)\n",
        "  text = lower_case(text)\n",
        "  text_tockens_created = tokenization(text)\n",
        "  text_tockens_created = remove_stpwords(text_tockens_created)\n",
        "  text_tockens_created = stemming(text_tockens_created)\n",
        "  text_tockens_created = lemmatizer(text_tockens_created)\n",
        "  return text_tockens_created"
      ],
      "id": "y-_VfUxRtg9r"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "c4278c07",
        "outputId": "04817afc-93f8-449d-c24e-0d335b6d3b6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-febb894b-2209-4b75-ac4f-88376a7340e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-febb894b-2209-4b75-ac4f-88376a7340e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-febb894b-2209-4b75-ac4f-88376a7340e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-febb894b-2209-4b75-ac4f-88376a7340e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head()"
      ],
      "id": "c4278c07"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "01e1710b"
      },
      "outputs": [],
      "source": [
        "#Preprocessing"
      ],
      "id": "01e1710b"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6b264205"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "id": "6b264205"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1d4b881d"
      },
      "outputs": [],
      "source": [
        "x = df['comment_text']\n",
        "\n",
        "y = df[df.columns[2:]].values"
      ],
      "id": "1d4b881d"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXu9CGUYEAvQ",
        "outputId": "7ade2acd-67ea-47d9-f79e-507aa4e05313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.getrecursionlimit()) # Prints 1000"
      ],
      "id": "FXu9CGUYEAvQ"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d575e26a",
        "outputId": "b7728248-b6d2-4f63-ce0d-b831e003d91d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         Explanation\\nWhy the edits made under my usern...\n",
            "1         D'aww! He matches this background colour I'm s...\n",
            "2         Hey man, I'm really not trying to edit war. It...\n",
            "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
            "4         You, sir, are my hero. Any chance you remember...\n",
            "                                ...                        \n",
            "159566    \":::::And for the second time of asking, when ...\n",
            "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
            "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
            "159569    And it looks like it was actually you who put ...\n",
            "159570    \"\\nAnd ... I really don't think you understand...\n",
            "Name: comment_text, Length: 159571, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ],
      "id": "d575e26a"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bbfd2aa",
        "outputId": "6f016904-6453-42dc-e3aa-4f4c19a1ed40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " ...\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ],
      "id": "1bbfd2aa"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c7369eaa"
      },
      "outputs": [],
      "source": [
        "MAX_FEATURES=200000 #number of words in the vocab"
      ],
      "id": "c7369eaa"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cde94790"
      },
      "outputs": [],
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length = 1800, output_mode='int')"
      ],
      "id": "cde94790"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e9bbc35c"
      },
      "outputs": [],
      "source": [
        "vectorizer.adapt(x.values) #trained vectorizer to learn our vocab"
      ],
      "id": "e9bbc35c"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa883445",
        "outputId": "dbd9fb86-e630-4427-c129-b77d3226aba7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1800,), dtype=int64, numpy=array([288, 263, 306, ...,   0,   0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "vectorizer(\"Hello world life is amazing\")"
      ],
      "id": "aa883445"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ac9b4fc1"
      },
      "outputs": [],
      "source": [
        "vectorized_text = vectorizer(x.values) #tokenized every single word in the vocab"
      ],
      "id": "ac9b4fc1"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81730d44",
        "outputId": "202654fd-7288-40f0-8094-6dc4599bb382"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
              "array([[  645,    76,     2, ...,     0,     0,     0],\n",
              "       [    1,    54,  2489, ...,     0,     0,     0],\n",
              "       [  425,   441,    70, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [32445,  7392,   383, ...,     0,     0,     0],\n",
              "       [    5,    12,   534, ...,     0,     0,     0],\n",
              "       [    5,     8,   130, ...,     0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "vectorized_text"
      ],
      "id": "81730d44"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "54eb9b5c"
      },
      "outputs": [],
      "source": [
        "#creating a tensorflow data pipeline\n",
        "#data pipeline steps - MCSHABAP Map, Cache, SHuffle, BAtch, Prefetch\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text,y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16) # divided into batches\n",
        "dataset = dataset.prefetch(8) # helps prevent bottlenecks"
      ],
      "id": "54eb9b5c"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "b219182a"
      },
      "outputs": [],
      "source": [
        "batch_x, batch_y = dataset.as_numpy_iterator().next()\n",
        "#batch represented as text + labels"
      ],
      "id": "b219182a"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3d1e86a",
        "outputId": "df7667cc-f430-46ad-f381-3d841d90677e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9974\n",
            "159584\n",
            "(16, 1800)\n",
            "(16, 6)\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset)) #this many number of batches now\n",
        "print(len(dataset)*16) #actual number\n",
        "#idea of shape\n",
        "print(batch_x.shape)\n",
        "print(batch_y.shape)"
      ],
      "id": "e3d1e86a"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4a6cd703"
      },
      "outputs": [],
      "source": [
        "train = dataset.take(int(len(dataset)*0.7)) #\"take\" that partition out as train data for training. Taking 70% data for train\n",
        "val = dataset.skip(int(len(dataset)*0.7)).take(int(len(dataset)*0.2))\n",
        "test = dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1))"
      ],
      "id": "4a6cd703"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e191d1a",
        "outputId": "ad9b8894-6827-49bb-8ecb-db361366afac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6981\n",
            "1994\n",
            "997\n"
          ]
        }
      ],
      "source": [
        "print(len(train))\n",
        "print(len(val))\n",
        "print(len(test))"
      ],
      "id": "5e191d1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "622def46"
      },
      "source": [
        "CREATE SEQUENTIAL MODEL"
      ],
      "id": "622def46"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8ca048f5"
      },
      "outputs": [],
      "source": [
        "#embedding layer groups similar words; creates word vectors and checks the angles between them\n",
        "#Personality test for the word: Words having similar scores are grouped e.g. great and good"
      ],
      "id": "8ca048f5"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "edd17874"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
      ],
      "id": "edd17874"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu3vsA2C_Xk0",
        "outputId": "29151992-1750-41c3-b591-827b160630c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 100)         1000100   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 256)        234496    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 256)         0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 64)          81984     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,335,434\n",
            "Trainable params: 1,335,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Conv1D, GlobalMaxPooling1D, concatenate\n",
        "\n",
        "MAX_FEATURES = 10000\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(Embedding(input_dim=MAX_FEATURES+1, output_dim=EMBEDDING_DIM))\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(units=128, activation='tanh', return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Convolutional layer\n",
        "model.add(Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=6, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "id": "Hu3vsA2C_Xk0"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "64f44d4b",
        "outputId": "c3928d2c-59b2-4f69-cf89-df8a10ba815c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel = Sequential()\\n#creating the embedding layer\\nmodel.add(Embedding(MAX_FEATURES+1,32))\\n#bidirectional: i dont like you (like read last; has + connotation) vs other direcion reading: you like dont i - connotation\\n#Bidirectional LSTM layer\\nmodel.add(Bidirectional(LSTM(32,activation='tanh')))\\n#feature extractor fully connected layers\\nmodel.add(Dense(128,activation='relu'))\\nmodel.add(Dense(256,activation='relu'))\\nmodel.add(Dense(128,activation='relu'))\\n#final layer\\nmodel.add(Dense(6,activation='sigmoid'))\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "'''\n",
        "model = Sequential()\n",
        "#creating the embedding layer\n",
        "model.add(Embedding(MAX_FEATURES+1,32))\n",
        "#bidirectional: i dont like you (like read last; has + connotation) vs other direcion reading: you like dont i - connotation\n",
        "#Bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(32,activation='tanh')))\n",
        "#feature extractor fully connected layers\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "#final layer\n",
        "model.add(Dense(6,activation='sigmoid'))'''"
      ],
      "id": "64f44d4b"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "68892b92"
      },
      "outputs": [],
      "source": [
        "#model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
      ],
      "id": "68892b92"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621fdb41",
        "outputId": "51a5d295-4cde-4f9d-9e38-f8e05414eb1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 100)         1000100   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 256)        234496    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 256)         0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 64)          81984     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,335,434\n",
            "Trainable params: 1,335,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ],
      "id": "621fdb41"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1539729",
        "outputId": "9d21e63e-2424-4f5f-e2e6-ed5af3b67ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "6981/6981 [==============================] - 1130s 159ms/step - loss: 0.0695 - accuracy: 0.9447 - val_loss: 0.0571 - val_accuracy: 0.9942\n",
            "Epoch 2/5\n",
            " 843/6981 [==>...........................] - ETA: 13:00 - loss: 0.0515 - accuracy: 0.9944"
          ]
        }
      ],
      "source": [
        "history = model.fit(train,epochs=5,validation_data=val)"
      ],
      "id": "f1539729"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "411de808"
      },
      "outputs": [],
      "source": [
        "history.history"
      ],
      "id": "411de808"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HsTcWuVw-Nz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training and validation loss and accuracy from the history dictionary\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
        "\n",
        "# Plot the training and validation loss on the first subplot\n",
        "ax1.plot(loss, label='Training Loss')\n",
        "# ax1.plot(val_loss, label='Validation Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training Loss')\n",
        "ax1.legend()\n",
        "\n",
        "# Plot the training and validation accuracy on the second subplot\n",
        "ax2.plot(accuracy, label='Training Accuracy')\n",
        "# ax2.plot(val_accuracy, label='Validation Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Training Accuracy')\n",
        "ax2.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "id": "-HsTcWuVw-Nz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8888c9e3"
      },
      "outputs": [],
      "source": [
        "batch_x, batch_y = test.as_numpy_iterator().next()"
      ],
      "id": "8888c9e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccc33468"
      },
      "outputs": [],
      "source": [
        "df.columns[2:]"
      ],
      "id": "ccc33468"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-ZzA67UvQpm"
      },
      "outputs": [],
      "source": [
        "(model.predict(batch_x) > 0.5).astype(int)"
      ],
      "id": "e-ZzA67UvQpm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci87oiC7vST6"
      },
      "outputs": [],
      "source": [
        "#Evaluation of model"
      ],
      "id": "Ci87oiC7vST6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7-wfnv-jIyb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
      ],
      "id": "j7-wfnv-jIyb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUZyWptzjTkg"
      },
      "outputs": [],
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()"
      ],
      "id": "ZUZyWptzjTkg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdvHZIE3jeQj"
      },
      "outputs": [],
      "source": [
        "for batch in test.as_numpy_iterator():\n",
        "  #unpack the batch\n",
        "  x_true, y_true = batch\n",
        "  #make a prediction\n",
        "  y_that = model.predict(x_true)\n",
        "\n",
        "  #flatten predictions\n",
        "  y_true = y_true.flatten()\n",
        "  y_that = y_that.flatten()\n",
        "\n",
        "  pre.update_state(y_true, y_that)\n",
        "  re.update_state(y_true, y_that)\n",
        "  acc.update_state(y_true, y_that)"
      ],
      "id": "GdvHZIE3jeQj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY9FDp_Gl_0L"
      },
      "outputs": [],
      "source": [
        "print(f'Precision: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')"
      ],
      "id": "xY9FDp_Gl_0L"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GgQ6T8TMDEU"
      },
      "outputs": [],
      "source": [
        "pres = pre.result().numpy()\n",
        "reca = re.result().numpy()"
      ],
      "id": "8GgQ6T8TMDEU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FcwTUz4LtOB"
      },
      "outputs": [],
      "source": [
        "f1 = 2*pres*reca/(pres+reca)"
      ],
      "id": "2FcwTUz4LtOB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq4cx0pSMfSn"
      },
      "outputs": [],
      "source": [
        "f1"
      ],
      "id": "Aq4cx0pSMfSn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKBFgfSb4tTB"
      },
      "outputs": [],
      "source": [
        "#APP"
      ],
      "id": "bKBFgfSb4tTB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k58eEM7243P9"
      },
      "outputs": [],
      "source": [
        "!pip install gradio jinja2"
      ],
      "id": "k58eEM7243P9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkVWE--z46iZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import gradio as gr"
      ],
      "id": "BkVWE--z46iZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVRgYhsw5AX2"
      },
      "outputs": [],
      "source": [
        "model.save('toxicity.h5')"
      ],
      "id": "IVRgYhsw5AX2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw5Tf4yf5X_G"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('toxicity.h5')"
      ],
      "id": "dw5Tf4yf5X_G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja-D8nd65hJV"
      },
      "outputs": [],
      "source": [
        "def score_comment(comment):\n",
        "  vectorized_comment = vectorizer([comment])\n",
        "  results = model.predict(vectorized_comment)\n",
        "\n",
        "  text = ''\n",
        "  for idx, col in enumerate(df.columns[2:-1]):\n",
        "    text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
        "\n",
        "  return text"
      ],
      "id": "ja-D8nd65hJV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzYtFycn6RVh"
      },
      "outputs": [],
      "source": [
        "interface = gr.Interface(fn=score_comment, inputs = gr.inputs.Textbox(lines=2, placeholder = 'Comment to score'), outputs = 'text')"
      ],
      "id": "CzYtFycn6RVh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elva-_my6sy3"
      },
      "outputs": [],
      "source": [
        "interface.launch(share=True)"
      ],
      "id": "elva-_my6sy3"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}